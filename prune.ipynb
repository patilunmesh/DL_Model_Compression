{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import logging\n",
    "import pickle\n",
    "from os.path import expanduser\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torchvision import transforms, datasets\n",
    "# Imports for plotting our result curves\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.utils.prune as prune\n",
    "home = expanduser(\"~/Model_compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR3(Dataset):\n",
    "\n",
    "    def __init__(self,split=\"train\",transform=None):\n",
    "      if split==\"train\":\n",
    "        with open(\"cifar10_hst_train\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo) \n",
    "      elif split==\"val\":\n",
    "        with open(\"cifar10_hst_val\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo)\n",
    "      else:\n",
    "        with open(\"cifar10_hst_test\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo)\n",
    "      \n",
    "      self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['labels'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.data['images'][idx,:]\n",
    "        r = x[:1024].reshape(32,32)\n",
    "        g = x[1024:2048].reshape(32,32)\n",
    "        b = x[2048:].reshape(32,32)\n",
    "        \n",
    "        x = Tensor(np.stack([r,g,b]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "          x = self.transform(x)\n",
    "        \n",
    "        y = self.data['labels'][idx,0]\n",
    "        return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.fc1 = nn.Linear(4096, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        #TODO\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.pool1(self.conv2(x)))\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = self.relu4(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        #print(x.shape, \"###########1\")\n",
    "        nff = self.num_flat_features(x)\n",
    "        x = x.view(-1 , nff)\n",
    "        #print(x.shape, \"###########\")\n",
    "        x = self.batchnorm1(self.fc1(x))\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean=[127.5, 127.5, 127.5],\n",
    "                             std=[127.5, 127.5, 127.5])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[127.5, 127.5, 127.5],\n",
    "                             std=[127.5, 127.5, 127.5])\n",
    "    ])\n",
    "\n",
    "train_data = CIFAR3(\"train\", transform=train_transform)\n",
    "val_data = CIFAR3(\"val\", transform=test_transform)\n",
    "test_data = CIFAR3(\"test\", transform=test_transform)\n",
    "\n",
    "batch_size = 256\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = Net()\n",
    "model_dict = torch.load(home+'/outputs/best_mode.pth')\n",
    "model.load_state_dict(model_dict['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module = model.conv1\n",
    "# module2 = model.conv2\n",
    "# module3 = model.conv3\n",
    "# module4 = model.conv4\n",
    "# module5 = model.conv5\n",
    "# #print(list(module.named_parameters()))\n",
    "# #print(list(module.named_buffers()))\n",
    "# prune.random_unstructured(module, name='weight', amount=0.3) \n",
    "# #print(list(module.named_parameters()))\n",
    "# #print(module.weight)\n",
    "# prune.l1_unstructured(module, name=\"bias\", amount=3)\n",
    "\n",
    "# parameters_to_prune = [\n",
    "#             (model.conv1, 'weight'),\n",
    "#             (model.conv2, 'weight'),\n",
    "#             (model.conv3, 'weight'),\n",
    "#             (model.conv4, 'weight'),\n",
    "#             (model.fc1, 'weight'),\n",
    "#             (model.fc2, 'weight'),\n",
    "#             ]\n",
    "# prune.global_unstructured(\n",
    "#             parameters_to_prune,\n",
    "#             pruning_method=prune.L1Unstructured,\n",
    "#             amount=0.9\n",
    "#             )\n",
    "#print(model._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_log = []\n",
    "acc_log = []\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "best_val_acc = 0.85\n",
    "for i in range(57):\n",
    "  parameters_to_prune = [\n",
    "            (model.conv1, 'weight'),\n",
    "            (model.conv2, 'weight'),\n",
    "            (model.conv3, 'weight'),\n",
    "            (model.conv4, 'weight'),\n",
    "            (model.fc1, 'weight'),\n",
    "            (model.fc2, 'weight'),\n",
    "            ]\n",
    "  prune.global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method=prune.L1Unstructured,\n",
    "            amount=0.45\n",
    "            )\n",
    "  #prune.random_unstructured(model.conv1, 'weight', 0.6)\n",
    "  # Run an epoch of training\n",
    "  train_running_loss = 0\n",
    "  train_running_acc = 0\n",
    "  model.train()\n",
    "  for j,input in enumerate(trainloader,0):\n",
    "   \n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "    out = model(x)\n",
    "    loss = criterion(out,y)\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    train_running_loss += loss.item()\n",
    "    train_running_acc += correct.item()\n",
    "    loss_log.append(loss.item())\n",
    "    acc_log.append(correct.item()/len(y))\n",
    "\n",
    "  train_running_loss /= j\n",
    "  train_running_acc /= len(train_data)\n",
    "\n",
    "  # Evaluate on validation\n",
    "  val_acc = 0\n",
    "  val_loss = 0\n",
    "  model.eval()\n",
    "  for j,input in enumerate(valloader,0):\n",
    "\n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "    \n",
    "    out = model(x)\n",
    "\n",
    "    loss = criterion(out,y)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    val_acc += correct.item()\n",
    "    val_loss += loss.item()\n",
    "\n",
    "  val_acc /= len(val_data)\n",
    "  val_loss /= j\n",
    "  prune.remove(model.conv1, 'weight')\n",
    "  prune.remove(model.conv2, 'weight')\n",
    "  prune.remove(model.conv3, 'weight')\n",
    "  prune.remove(model.conv4, 'weight')\n",
    "  prune.remove(model.fc1, 'weight')\n",
    "  prune.remove(model.fc2, 'weight')\n",
    "  if val_acc > best_val_acc and i > 2:\n",
    "    best_val_acc = val_acc\n",
    "    print(\"saving model\")\n",
    "    torch.save({\n",
    "                'epoch': i+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, home+'/outputs/prune45.pth')\n",
    "    \n",
    "  val_acc_log.append(val_acc)\n",
    "\n",
    "  val_loss_log.append(val_loss)\n",
    "\n",
    "  logging.info(\"[Epoch {:3}]   Loss:  {:8.4}     Train Acc:  {:8.4}%      Val Acc:  {:8.4}%\".format(i,train_running_loss, train_running_acc*100,val_acc*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2165795\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(pytorch_total_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
