{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knowledge distillation!\n",
    "#teacher net student net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import logging\n",
    "import pickle\n",
    "from os.path import expanduser\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "home = expanduser(\"~/Model_compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR3(Dataset):\n",
    "\n",
    "    def __init__(self,split=\"train\",transform=None):\n",
    "      if split==\"train\":\n",
    "        with open(\"cifar10_hst_train\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo) \n",
    "      elif split==\"val\":\n",
    "        with open(\"cifar10_hst_val\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo)\n",
    "      else:\n",
    "        with open(\"cifar10_hst_test\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo)\n",
    "      \n",
    "      self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['labels'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.data['images'][idx,:]\n",
    "        r = x[:1024].reshape(32,32)\n",
    "        g = x[1024:2048].reshape(32,32)\n",
    "        b = x[2048:].reshape(32,32)\n",
    "        \n",
    "        x = Tensor(np.stack([r,g,b]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "          x = self.transform(x)\n",
    "        \n",
    "        y = self.data['labels'][idx,0]\n",
    "        return x,y \n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean=[127.5, 127.5, 127.5],\n",
    "                             std=[127.5, 127.5, 127.5])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[127.5, 127.5, 127.5],\n",
    "                             std=[127.5, 127.5, 127.5])\n",
    "    ])\n",
    "\n",
    "train_data = CIFAR3(\"train\", transform=train_transform)\n",
    "val_data = CIFAR3(\"val\", transform=test_transform)\n",
    "test_data = CIFAR3(\"test\", transform=test_transform)\n",
    "\n",
    "batch_size = 256\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teacher\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.fc1 = nn.Linear(4096, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        #TODO\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.pool1(self.conv2(x)))\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = self.relu4(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        #print(x.shape, \"###########1\")\n",
    "        nff = self.num_flat_features(x)\n",
    "        x = x.view(-1 , nff)\n",
    "        #print(x.shape, \"###########\")\n",
    "        x = self.batchnorm1(self.fc1(x))\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "class SNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1, stride=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        #TODO\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.pool1(self.conv2(x)))\n",
    "        #print(\"#####################3\", x.shape)\n",
    "        #x = self.relu3(self.pool2(self.conv3(x)))\n",
    "        nff = self.num_flat_features(x)\n",
    "        x = x.view(-1 , nff)\n",
    "        #print(x.shape, \"###########\")\n",
    "        x = self.batchnorm1(self.fc1(x))\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tester(model, valloader, length):\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    device = 'cpu'\n",
    "    for j,input in enumerate(valloader,0):\n",
    "\n",
    "        x = input[0].to(device)\n",
    "        y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "        \n",
    "        out = model(x)\n",
    "\n",
    "        loss = criterion(out,y)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct = (predicted == y).sum()\n",
    "\n",
    "        val_acc += correct.item()\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    val_acc /= length\n",
    "    val_loss /= j\n",
    "    return val_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trainiing student only 90% max\n",
    "# Build model\n",
    "smodel = SNet()\n",
    "\n",
    "\n",
    "# Main training loop\n",
    "optimizer = torch.optim.Adam(smodel.parameters(), lr=1e-4, weight_decay=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "smodel.to(device)\n",
    "loss_log = []\n",
    "acc_log = []\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "best_val_acc = 0.0\n",
    "for i in range(50):\n",
    "\n",
    "  # Run an epoch of training\n",
    "  train_running_loss = 0\n",
    "  train_running_acc = 0\n",
    "  smodel.train()\n",
    "  for j,input in enumerate(trainloader,0):\n",
    "   \n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "    out = smodel(x)\n",
    "    loss = criterion(out,y)\n",
    "\n",
    "    smodel.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    train_running_loss += loss.item()\n",
    "    train_running_acc += correct.item()\n",
    "    loss_log.append(loss.item())\n",
    "    acc_log.append(correct.item()/len(y))\n",
    "\n",
    "  train_running_loss /= j\n",
    "  train_running_acc /= len(train_data)\n",
    "\n",
    "  # Evaluate on validation\n",
    "  val_acc = 0\n",
    "  val_loss = 0\n",
    "  smodel.eval()\n",
    "  for j,input in enumerate(valloader,0):\n",
    "\n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "    \n",
    "    out = smodel(x)\n",
    "\n",
    "    loss = criterion(out,y)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    val_acc += correct.item()\n",
    "    val_loss += loss.item()\n",
    "\n",
    "  val_acc /= len(val_data)\n",
    "  val_loss /= j\n",
    "  if val_acc > best_val_acc:\n",
    "    best_val_acc = val_acc\n",
    "    print(\"saving model\")\n",
    "    torch.save({\n",
    "                'epoch': i+1,\n",
    "                'model_state_dict': smodel.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, home+'/outputs/student_model2.pth')\n",
    "    \n",
    "  val_acc_log.append(val_acc)\n",
    "\n",
    "  val_loss_log.append(val_loss)\n",
    "\n",
    "  logging.info(\"[Epoch {:3}]   Loss:  {:8.4}     Train Acc:  {:8.4}%      Val Acc:  {:8.4}%\".format(i,train_running_loss, train_running_acc*100,val_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528755\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in smodel.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.perf_counter()\n",
    "valaccu = my_tester(smodel, testloader, len(test_data))\n",
    "toc = time.perf_counter()\n",
    "print(valaccu, \" orig time \", toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training teacher only\n",
    "import copy\n",
    "model = Net()\n",
    "model_dict = torch.load(home+'/outputs/best_mode.pth')\n",
    "model.load_state_dict(model_dict['model_state_dict'])\n",
    "\n",
    "\n",
    "# Main training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "loss_log = []\n",
    "acc_log = []\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "best_val_acc = 0.0\n",
    "for i in range(50):\n",
    "\n",
    "  # Run an epoch of training\n",
    "  train_running_loss = 0\n",
    "  train_running_acc = 0\n",
    "  model.train()\n",
    "  for j,input in enumerate(trainloader,0):\n",
    "   \n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "    out = model(x)\n",
    "    loss = criterion(out,y)\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    train_running_loss += loss.item()\n",
    "    train_running_acc += correct.item()\n",
    "    loss_log.append(loss.item())\n",
    "    acc_log.append(correct.item()/len(y))\n",
    "\n",
    "  train_running_loss /= j\n",
    "  train_running_acc /= len(train_data)\n",
    "\n",
    "  # Evaluate on validation\n",
    "  val_acc = 0\n",
    "  val_loss = 0\n",
    "  model.eval()\n",
    "  for j,input in enumerate(valloader,0):\n",
    "\n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "    \n",
    "    out = model(x)\n",
    "\n",
    "    loss = criterion(out,y)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    val_acc += correct.item()\n",
    "    val_loss += loss.item()\n",
    "\n",
    "  val_acc /= len(val_data)\n",
    "  val_loss /= j\n",
    "  if val_acc > best_val_acc:\n",
    "    best_val_acc = val_acc\n",
    "    teacher_model = copy.deepcopy(model)\n",
    "    print(\"saving model\")\n",
    "    torch.save({\n",
    "                'epoch': i+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, home+'/outputs/teacher_model.pth')\n",
    "    \n",
    "  val_acc_log.append(val_acc)\n",
    "\n",
    "  val_loss_log.append(val_loss)\n",
    "\n",
    "  logging.info(\"[Epoch {:3}]   Loss:  {:8.4}     Train Acc:  {:8.4}%      Val Acc:  {:8.4}%\".format(i,train_running_loss, train_running_acc*100,val_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.perf_counter()\n",
    "valaccu = my_tester(model, testloader, len(test_data))\n",
    "toc = time.perf_counter()\n",
    "print(valaccu, \" orig time \", toc - tic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distillation begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output directory and create if needed\n",
    "import os\n",
    "output_dir = \"small_linear_model_distill1/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define our custom loss function\n",
    "softmax_op = nn.Softmax(dim=1)\n",
    "mseloss_fn = nn.MSELoss()\n",
    "\n",
    "def my_loss(scores, targets, T=1): #simple mse loss\n",
    "    soft_pred = softmax_op(scores / T)\n",
    "    soft_targets = softmax_op(targets / T)\n",
    "    loss = mseloss_fn(soft_pred, soft_targets)\n",
    "    return loss\n",
    "\n",
    "def loss_kd(outputs, labels, teacher_outputs): #kl divergence loss\n",
    "   temparature =1\n",
    "   alpha = 0.5\n",
    "   KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/temparature, dim=1),F.softmax(teacher_outputs/temparature,dim=1)) *(alpha * temparature * temparature) + F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "   return KD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:26:08 INFO     [Epoch   0]   Loss:     0.468     Train Acc:     70.08%      Val Acc:      78.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:26:25 INFO     [Epoch   1]   Loss:    0.3339     Train Acc:     80.28%      Val Acc:      82.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:26:43 INFO     [Epoch   2]   Loss:    0.2928     Train Acc:     82.46%      Val Acc:      83.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:27:00 INFO     [Epoch   3]   Loss:      0.27     Train Acc:     84.05%      Val Acc:     86.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:27:16 INFO     [Epoch   4]   Loss:    0.2486     Train Acc:     85.17%      Val Acc:      87.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:27:33 INFO     [Epoch   5]   Loss:    0.2323     Train Acc:     86.12%      Val Acc:     87.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:27:48 INFO     [Epoch   6]   Loss:    0.2223     Train Acc:     86.95%      Val Acc:     88.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:28:03 INFO     [Epoch   7]   Loss:    0.2134     Train Acc:     87.49%      Val Acc:     88.35%\n",
      "2023-06-16 17:28:17 INFO     [Epoch   8]   Loss:     0.208     Train Acc:     87.53%      Val Acc:     88.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:28:32 INFO     [Epoch   9]   Loss:    0.2015     Train Acc:     88.17%      Val Acc:      89.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:28:46 INFO     [Epoch  10]   Loss:    0.1945     Train Acc:     88.46%      Val Acc:      89.5%\n",
      "2023-06-16 17:29:01 INFO     [Epoch  11]   Loss:    0.1887     Train Acc:      88.7%      Val Acc:      89.4%\n",
      "2023-06-16 17:29:16 INFO     [Epoch  12]   Loss:    0.1854     Train Acc:     89.16%      Val Acc:      89.5%\n",
      "2023-06-16 17:29:31 INFO     [Epoch  13]   Loss:    0.1818     Train Acc:     89.17%      Val Acc:      89.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:29:46 INFO     [Epoch  14]   Loss:    0.1792     Train Acc:     89.55%      Val Acc:     90.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:30:03 INFO     [Epoch  15]   Loss:    0.1745     Train Acc:     89.63%      Val Acc:     90.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:30:18 INFO     [Epoch  16]   Loss:    0.1712     Train Acc:     89.76%      Val Acc:      90.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:30:33 INFO     [Epoch  17]   Loss:    0.1693     Train Acc:     90.02%      Val Acc:     89.95%\n",
      "2023-06-16 17:30:48 INFO     [Epoch  18]   Loss:    0.1642     Train Acc:     90.41%      Val Acc:     90.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:31:03 INFO     [Epoch  19]   Loss:    0.1596     Train Acc:     90.68%      Val Acc:     90.75%\n",
      "2023-06-16 17:31:18 INFO     [Epoch  20]   Loss:    0.1583     Train Acc:     90.72%      Val Acc:     91.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:31:33 INFO     [Epoch  21]   Loss:    0.1558     Train Acc:     90.98%      Val Acc:     91.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:31:49 INFO     [Epoch  22]   Loss:     0.153     Train Acc:     91.16%      Val Acc:      91.1%\n",
      "2023-06-16 17:32:04 INFO     [Epoch  23]   Loss:    0.1529     Train Acc:     90.96%      Val Acc:      90.9%\n",
      "2023-06-16 17:32:18 INFO     [Epoch  24]   Loss:    0.1483     Train Acc:     91.31%      Val Acc:      91.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:32:33 INFO     [Epoch  25]   Loss:    0.1438     Train Acc:     91.48%      Val Acc:     91.55%\n",
      "2023-06-16 17:32:49 INFO     [Epoch  26]   Loss:    0.1472     Train Acc:     91.27%      Val Acc:     91.25%\n",
      "2023-06-16 17:33:04 INFO     [Epoch  27]   Loss:    0.1432     Train Acc:     91.66%      Val Acc:      91.3%\n",
      "2023-06-16 17:33:19 INFO     [Epoch  28]   Loss:    0.1399     Train Acc:     91.99%      Val Acc:     91.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:33:34 INFO     [Epoch  29]   Loss:    0.1389     Train Acc:     91.96%      Val Acc:      91.3%\n",
      "2023-06-16 17:33:49 INFO     [Epoch  30]   Loss:     0.135     Train Acc:     92.18%      Val Acc:     91.45%\n",
      "2023-06-16 17:34:03 INFO     [Epoch  31]   Loss:    0.1334     Train Acc:     92.39%      Val Acc:     91.45%\n",
      "2023-06-16 17:34:18 INFO     [Epoch  32]   Loss:    0.1335     Train Acc:     92.08%      Val Acc:     91.35%\n",
      "2023-06-16 17:34:34 INFO     [Epoch  33]   Loss:    0.1314     Train Acc:     92.44%      Val Acc:     91.75%\n",
      "2023-06-16 17:34:52 INFO     [Epoch  34]   Loss:    0.1288     Train Acc:     92.55%      Val Acc:      91.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:35:08 INFO     [Epoch  35]   Loss:    0.1269     Train Acc:     92.84%      Val Acc:      91.7%\n",
      "2023-06-16 17:35:24 INFO     [Epoch  36]   Loss:    0.1272     Train Acc:     92.65%      Val Acc:     91.25%\n",
      "2023-06-16 17:35:44 INFO     [Epoch  37]   Loss:     0.124     Train Acc:     92.92%      Val Acc:      91.5%\n",
      "2023-06-16 17:36:02 INFO     [Epoch  38]   Loss:    0.1215     Train Acc:     93.21%      Val Acc:     91.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:36:20 INFO     [Epoch  39]   Loss:    0.1196     Train Acc:     93.15%      Val Acc:     91.75%\n",
      "2023-06-16 17:36:38 INFO     [Epoch  40]   Loss:    0.1199     Train Acc:     93.32%      Val Acc:     91.65%\n",
      "2023-06-16 17:36:56 INFO     [Epoch  41]   Loss:    0.1198     Train Acc:     92.97%      Val Acc:     92.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:37:15 INFO     [Epoch  42]   Loss:    0.1183     Train Acc:     93.21%      Val Acc:      91.9%\n",
      "2023-06-16 17:37:32 INFO     [Epoch  43]   Loss:     0.115     Train Acc:     93.47%      Val Acc:      92.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:37:49 INFO     [Epoch  44]   Loss:    0.1152     Train Acc:     93.22%      Val Acc:     91.65%\n",
      "2023-06-16 17:38:06 INFO     [Epoch  45]   Loss:    0.1144     Train Acc:     93.44%      Val Acc:      92.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:38:23 INFO     [Epoch  46]   Loss:    0.1128     Train Acc:     93.71%      Val Acc:     92.65%\n",
      "2023-06-16 17:38:40 INFO     [Epoch  47]   Loss:    0.1112     Train Acc:     93.72%      Val Acc:      92.2%\n",
      "2023-06-16 17:38:55 INFO     [Epoch  48]   Loss:    0.1099     Train Acc:     93.74%      Val Acc:     92.55%\n",
      "2023-06-16 17:39:10 INFO     [Epoch  49]   Loss:    0.1107     Train Acc:     93.82%      Val Acc:      92.7%\n",
      "2023-06-16 17:39:26 INFO     [Epoch  50]   Loss:    0.1065     Train Acc:     94.07%      Val Acc:     92.75%\n",
      "2023-06-16 17:39:41 INFO     [Epoch  51]   Loss:    0.1062     Train Acc:     93.97%      Val Acc:      92.8%\n",
      "2023-06-16 17:39:56 INFO     [Epoch  52]   Loss:    0.1061     Train Acc:     94.01%      Val Acc:     92.75%\n",
      "2023-06-16 17:40:12 INFO     [Epoch  53]   Loss:    0.1044     Train Acc:     94.02%      Val Acc:     91.75%\n",
      "2023-06-16 17:40:27 INFO     [Epoch  54]   Loss:    0.1047     Train Acc:     94.01%      Val Acc:      91.2%\n",
      "2023-06-16 17:40:43 INFO     [Epoch  55]   Loss:    0.1008     Train Acc:     94.35%      Val Acc:      92.6%\n",
      "2023-06-16 17:41:00 INFO     [Epoch  56]   Loss:     0.103     Train Acc:     94.09%      Val Acc:      92.6%\n",
      "2023-06-16 17:41:18 INFO     [Epoch  57]   Loss:    0.1011     Train Acc:     94.42%      Val Acc:     92.55%\n",
      "2023-06-16 17:41:35 INFO     [Epoch  58]   Loss:     0.102     Train Acc:     94.01%      Val Acc:     93.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:41:51 INFO     [Epoch  59]   Loss:   0.09994     Train Acc:      94.5%      Val Acc:     92.85%\n",
      "2023-06-16 17:42:08 INFO     [Epoch  60]   Loss:   0.09887     Train Acc:     94.49%      Val Acc:      92.2%\n",
      "2023-06-16 17:42:23 INFO     [Epoch  61]   Loss:   0.09738     Train Acc:      94.6%      Val Acc:      92.6%\n",
      "2023-06-16 17:42:38 INFO     [Epoch  62]   Loss:   0.09581     Train Acc:     94.81%      Val Acc:     92.65%\n",
      "2023-06-16 17:42:53 INFO     [Epoch  63]   Loss:   0.09458     Train Acc:     94.78%      Val Acc:      92.5%\n",
      "2023-06-16 17:43:08 INFO     [Epoch  64]   Loss:   0.09381     Train Acc:      94.9%      Val Acc:      92.3%\n",
      "2023-06-16 17:43:23 INFO     [Epoch  65]   Loss:   0.09397     Train Acc:     94.82%      Val Acc:     93.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:43:38 INFO     [Epoch  66]   Loss:    0.0917     Train Acc:     94.94%      Val Acc:     92.85%\n",
      "2023-06-16 17:43:54 INFO     [Epoch  67]   Loss:   0.09079     Train Acc:     94.87%      Val Acc:     92.95%\n",
      "2023-06-16 17:44:10 INFO     [Epoch  68]   Loss:   0.09011     Train Acc:     95.08%      Val Acc:      92.9%\n",
      "2023-06-16 17:44:25 INFO     [Epoch  69]   Loss:   0.09179     Train Acc:     95.07%      Val Acc:      92.7%\n",
      "2023-06-16 17:44:41 INFO     [Epoch  70]   Loss:   0.09025     Train Acc:     95.05%      Val Acc:     92.85%\n",
      "2023-06-16 17:44:58 INFO     [Epoch  71]   Loss:   0.08752     Train Acc:     95.33%      Val Acc:     92.85%\n",
      "2023-06-16 17:45:16 INFO     [Epoch  72]   Loss:   0.08683     Train Acc:     95.28%      Val Acc:     92.75%\n",
      "2023-06-16 17:45:33 INFO     [Epoch  73]   Loss:   0.08903     Train Acc:     95.16%      Val Acc:      93.0%\n",
      "2023-06-16 17:45:51 INFO     [Epoch  74]   Loss:   0.08621     Train Acc:     95.13%      Val Acc:      93.0%\n",
      "2023-06-16 17:46:08 INFO     [Epoch  75]   Loss:    0.0849     Train Acc:     95.32%      Val Acc:     93.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:46:26 INFO     [Epoch  76]   Loss:   0.08301     Train Acc:     95.73%      Val Acc:      93.2%\n",
      "2023-06-16 17:46:43 INFO     [Epoch  77]   Loss:    0.0861     Train Acc:     95.34%      Val Acc:      93.3%\n",
      "2023-06-16 17:46:59 INFO     [Epoch  78]   Loss:   0.08394     Train Acc:      95.5%      Val Acc:      93.3%\n",
      "2023-06-16 17:47:16 INFO     [Epoch  79]   Loss:   0.08432     Train Acc:     95.51%      Val Acc:     92.55%\n",
      "2023-06-16 17:47:33 INFO     [Epoch  80]   Loss:   0.08275     Train Acc:     95.65%      Val Acc:      93.4%\n",
      "2023-06-16 17:47:49 INFO     [Epoch  81]   Loss:   0.08062     Train Acc:     95.58%      Val Acc:      93.3%\n",
      "2023-06-16 17:48:04 INFO     [Epoch  82]   Loss:   0.08001     Train Acc:     95.85%      Val Acc:      92.3%\n",
      "2023-06-16 17:48:19 INFO     [Epoch  83]   Loss:   0.08265     Train Acc:      95.8%      Val Acc:      93.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:48:33 INFO     [Epoch  84]   Loss:   0.08026     Train Acc:      95.6%      Val Acc:     92.75%\n",
      "2023-06-16 17:48:49 INFO     [Epoch  85]   Loss:   0.08105     Train Acc:     95.68%      Val Acc:     93.35%\n",
      "2023-06-16 17:49:04 INFO     [Epoch  86]   Loss:   0.08026     Train Acc:     95.76%      Val Acc:      93.8%\n",
      "2023-06-16 17:49:19 INFO     [Epoch  87]   Loss:   0.07809     Train Acc:     96.02%      Val Acc:     93.75%\n",
      "2023-06-16 17:49:35 INFO     [Epoch  88]   Loss:   0.07716     Train Acc:     95.97%      Val Acc:      94.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:49:49 INFO     [Epoch  89]   Loss:   0.07859     Train Acc:     95.88%      Val Acc:     93.85%\n",
      "2023-06-16 17:50:05 INFO     [Epoch  90]   Loss:   0.07791     Train Acc:     95.88%      Val Acc:     93.65%\n",
      "2023-06-16 17:50:22 INFO     [Epoch  91]   Loss:   0.07515     Train Acc:      95.8%      Val Acc:     92.45%\n",
      "2023-06-16 17:50:39 INFO     [Epoch  92]   Loss:   0.07556     Train Acc:     96.11%      Val Acc:     93.75%\n",
      "2023-06-16 17:50:57 INFO     [Epoch  93]   Loss:   0.07447     Train Acc:      96.3%      Val Acc:      93.0%\n",
      "2023-06-16 17:51:12 INFO     [Epoch  94]   Loss:   0.07646     Train Acc:     95.97%      Val Acc:      93.8%\n",
      "2023-06-16 17:51:26 INFO     [Epoch  95]   Loss:   0.07426     Train Acc:     96.43%      Val Acc:     93.65%\n",
      "2023-06-16 17:51:41 INFO     [Epoch  96]   Loss:   0.07347     Train Acc:     96.28%      Val Acc:      92.5%\n",
      "2023-06-16 17:51:57 INFO     [Epoch  97]   Loss:   0.07387     Train Acc:      96.0%      Val Acc:      93.7%\n",
      "2023-06-16 17:52:14 INFO     [Epoch  98]   Loss:   0.07434     Train Acc:     96.23%      Val Acc:      93.8%\n",
      "2023-06-16 17:52:31 INFO     [Epoch  99]   Loss:   0.07219     Train Acc:     96.56%      Val Acc:     93.05%\n",
      "2023-06-16 17:52:47 INFO     [Epoch 100]   Loss:   0.07524     Train Acc:     96.05%      Val Acc:     93.45%\n",
      "2023-06-16 17:53:01 INFO     [Epoch 101]   Loss:    0.0734     Train Acc:     96.11%      Val Acc:     93.75%\n",
      "2023-06-16 17:53:18 INFO     [Epoch 102]   Loss:   0.07311     Train Acc:     96.22%      Val Acc:     93.95%\n",
      "2023-06-16 17:53:35 INFO     [Epoch 103]   Loss:   0.07061     Train Acc:     96.42%      Val Acc:      94.1%\n",
      "2023-06-16 17:53:52 INFO     [Epoch 104]   Loss:   0.07008     Train Acc:     96.33%      Val Acc:      93.7%\n",
      "2023-06-16 17:54:10 INFO     [Epoch 105]   Loss:   0.07191     Train Acc:     96.25%      Val Acc:     92.85%\n",
      "2023-06-16 17:54:27 INFO     [Epoch 106]   Loss:   0.07104     Train Acc:     96.25%      Val Acc:      93.6%\n",
      "2023-06-16 17:54:45 INFO     [Epoch 107]   Loss:    0.0703     Train Acc:     96.58%      Val Acc:      94.0%\n",
      "2023-06-16 17:55:03 INFO     [Epoch 108]   Loss:   0.06863     Train Acc:     96.63%      Val Acc:      94.0%\n",
      "2023-06-16 17:55:20 INFO     [Epoch 109]   Loss:   0.06956     Train Acc:     96.38%      Val Acc:     94.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 17:55:38 INFO     [Epoch 110]   Loss:   0.06789     Train Acc:     96.45%      Val Acc:     94.35%\n",
      "2023-06-16 17:55:55 INFO     [Epoch 111]   Loss:   0.06674     Train Acc:     96.77%      Val Acc:      94.3%\n",
      "2023-06-16 17:56:13 INFO     [Epoch 112]   Loss:   0.06588     Train Acc:     96.56%      Val Acc:      93.7%\n",
      "2023-06-16 17:56:30 INFO     [Epoch 113]   Loss:   0.06667     Train Acc:     96.61%      Val Acc:     93.75%\n",
      "2023-06-16 17:56:48 INFO     [Epoch 114]   Loss:   0.06664     Train Acc:     96.56%      Val Acc:      93.8%\n",
      "2023-06-16 17:57:05 INFO     [Epoch 115]   Loss:   0.06594     Train Acc:     96.77%      Val Acc:     94.15%\n",
      "2023-06-16 17:57:22 INFO     [Epoch 116]   Loss:   0.06677     Train Acc:      96.7%      Val Acc:     94.25%\n",
      "2023-06-16 17:57:39 INFO     [Epoch 117]   Loss:   0.06571     Train Acc:     96.86%      Val Acc:      94.2%\n",
      "2023-06-16 17:57:56 INFO     [Epoch 118]   Loss:   0.06743     Train Acc:     96.53%      Val Acc:     93.55%\n",
      "2023-06-16 17:58:14 INFO     [Epoch 119]   Loss:   0.06527     Train Acc:     96.78%      Val Acc:      94.2%\n",
      "2023-06-16 17:58:32 INFO     [Epoch 120]   Loss:    0.0647     Train Acc:     96.85%      Val Acc:      94.0%\n",
      "2023-06-16 17:58:50 INFO     [Epoch 121]   Loss:   0.06422     Train Acc:     96.95%      Val Acc:      94.2%\n",
      "2023-06-16 17:59:08 INFO     [Epoch 122]   Loss:   0.06442     Train Acc:     96.82%      Val Acc:     94.35%\n",
      "2023-06-16 17:59:25 INFO     [Epoch 123]   Loss:   0.06504     Train Acc:     96.91%      Val Acc:     94.15%\n",
      "2023-06-16 17:59:43 INFO     [Epoch 124]   Loss:   0.06399     Train Acc:     97.05%      Val Acc:      94.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:00:01 INFO     [Epoch 125]   Loss:   0.06324     Train Acc:     96.66%      Val Acc:     93.75%\n",
      "2023-06-16 18:00:18 INFO     [Epoch 126]   Loss:   0.06194     Train Acc:     97.03%      Val Acc:     93.95%\n",
      "2023-06-16 18:00:35 INFO     [Epoch 127]   Loss:    0.0612     Train Acc:     97.12%      Val Acc:     93.95%\n",
      "2023-06-16 18:00:52 INFO     [Epoch 128]   Loss:   0.06144     Train Acc:     96.99%      Val Acc:      94.5%\n",
      "2023-06-16 18:01:09 INFO     [Epoch 129]   Loss:   0.06153     Train Acc:     97.07%      Val Acc:      92.9%\n",
      "2023-06-16 18:01:26 INFO     [Epoch 130]   Loss:   0.06333     Train Acc:     96.85%      Val Acc:      93.5%\n",
      "2023-06-16 18:01:43 INFO     [Epoch 131]   Loss:   0.06289     Train Acc:     96.95%      Val Acc:      92.9%\n",
      "2023-06-16 18:02:01 INFO     [Epoch 132]   Loss:   0.06221     Train Acc:      97.1%      Val Acc:     94.45%\n",
      "2023-06-16 18:02:18 INFO     [Epoch 133]   Loss:   0.06237     Train Acc:     96.93%      Val Acc:      93.1%\n",
      "2023-06-16 18:02:36 INFO     [Epoch 134]   Loss:   0.06029     Train Acc:     97.28%      Val Acc:     93.65%\n",
      "2023-06-16 18:02:54 INFO     [Epoch 135]   Loss:   0.06139     Train Acc:     97.07%      Val Acc:      94.1%\n",
      "2023-06-16 18:03:11 INFO     [Epoch 136]   Loss:   0.05975     Train Acc:     97.25%      Val Acc:     94.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:03:29 INFO     [Epoch 137]   Loss:   0.05958     Train Acc:     97.17%      Val Acc:     94.25%\n",
      "2023-06-16 18:03:47 INFO     [Epoch 138]   Loss:   0.05998     Train Acc:     97.08%      Val Acc:     93.85%\n",
      "2023-06-16 18:04:04 INFO     [Epoch 139]   Loss:   0.06039     Train Acc:     97.09%      Val Acc:      93.7%\n",
      "2023-06-16 18:04:22 INFO     [Epoch 140]   Loss:   0.06366     Train Acc:     96.87%      Val Acc:      93.5%\n",
      "2023-06-16 18:04:40 INFO     [Epoch 141]   Loss:   0.05978     Train Acc:      97.1%      Val Acc:      94.5%\n",
      "2023-06-16 18:04:58 INFO     [Epoch 142]   Loss:   0.05991     Train Acc:     97.02%      Val Acc:      93.4%\n",
      "2023-06-16 18:05:16 INFO     [Epoch 143]   Loss:   0.05923     Train Acc:     97.17%      Val Acc:      93.1%\n",
      "2023-06-16 18:05:33 INFO     [Epoch 144]   Loss:   0.05866     Train Acc:     97.46%      Val Acc:      94.5%\n",
      "2023-06-16 18:05:50 INFO     [Epoch 145]   Loss:   0.05796     Train Acc:     97.38%      Val Acc:     93.15%\n",
      "2023-06-16 18:06:07 INFO     [Epoch 146]   Loss:    0.0587     Train Acc:     97.15%      Val Acc:      93.8%\n",
      "2023-06-16 18:06:24 INFO     [Epoch 147]   Loss:    0.0588     Train Acc:     97.22%      Val Acc:     94.35%\n",
      "2023-06-16 18:06:40 INFO     [Epoch 148]   Loss:    0.0584     Train Acc:     97.32%      Val Acc:     94.25%\n",
      "2023-06-16 18:06:55 INFO     [Epoch 149]   Loss:   0.05598     Train Acc:     97.49%      Val Acc:      94.2%\n"
     ]
    }
   ],
   "source": [
    "#trainiing distilled student \n",
    "# Build model\n",
    "#editing\n",
    "dsmodel = SNet()\n",
    "# smodel_dict = torch.load(home+'/outputs/distil_original.pth')\n",
    "# dsmodel.load_state_dict(smodel_dict['model_state_dict'])\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "teacher_model = Net()\n",
    "tmodel_dict = torch.load(home+'/outputs/best_prune.pth')\n",
    "teacher_model.load_state_dict(tmodel_dict['model_state_dict'])\n",
    "teacher_model.eval()\n",
    "# Main training loop\n",
    "optimizer = torch.optim.Adam(dsmodel.parameters(), lr=1e-4, weight_decay=0.001)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "dsmodel.to(device)\n",
    "loss_log = []\n",
    "acc_log = []\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "best_val_acc = 0.0\n",
    "for i in range(150):\n",
    "\n",
    "  # Run an epoch of training\n",
    "  train_running_loss = 0\n",
    "  train_running_acc = 0\n",
    "  dsmodel.train()\n",
    "  for j,input in enumerate(trainloader,0):\n",
    "   \n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "    out = dsmodel(x)\n",
    "    targets = teacher_model(x)\n",
    "    #loss = my_loss(out, targets)\n",
    "    #loss = criterion(out, targets)\n",
    "    loss = loss_kd(out, y, targets)\n",
    "\n",
    "    dsmodel.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    train_running_loss += loss.item()\n",
    "    train_running_acc += correct.item()\n",
    "    loss_log.append(loss.item())\n",
    "    acc_log.append(correct.item()/len(y))\n",
    "\n",
    "  train_running_loss /= j\n",
    "  train_running_acc /= len(train_data)\n",
    "\n",
    "  # Evaluate on validation\n",
    "  val_acc = 0\n",
    "  val_loss = 0\n",
    "  dsmodel.eval()\n",
    "  for j,input in enumerate(valloader,0):\n",
    "\n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "    \n",
    "    out = dsmodel(x)\n",
    "    #targets = teacher_model(x)\n",
    "    loss2 = criterion(out, y)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    val_acc += correct.item()\n",
    "    val_loss += loss2.item()\n",
    "\n",
    "  val_acc /= len(val_data)\n",
    "  val_loss /= j\n",
    "  if val_acc > best_val_acc:\n",
    "    best_val_acc = val_acc\n",
    "    print(\"saving model\")\n",
    "    torch.save({\n",
    "                'epoch': i+1,\n",
    "                'model_state_dict': dsmodel.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, '/home/hlab/Classes/outputs/distil_prune.pth')\n",
    "    \n",
    "  val_acc_log.append(val_acc)\n",
    "\n",
    "  val_loss_log.append(val_loss)\n",
    "\n",
    "  logging.info(\"[Epoch {:3}]   Loss:  {:8.4}     Train Acc:  {:8.4}%      Val Acc:  {:8.4}%\".format(i,train_running_loss, train_running_acc*100,val_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528755\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in dsmodel.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_tester2(model, valloader, length):\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    device = 'cpu'\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for j,input in enumerate(valloader,0):\n",
    "\n",
    "        x = input[0].to(device)\n",
    "        y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "        \n",
    "        out = model(x)\n",
    "\n",
    "        loss = criterion(out,y)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct = (predicted == y).sum()\n",
    "\n",
    "        val_acc += correct.item()\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    val_acc /= length\n",
    "    val_loss /= j\n",
    "    return val_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.53333333333333  orig time  0.2758444450009847\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.perf_counter()\n",
    "valaccu = my_tester2(dsmodel, testloader, len(test_data))\n",
    "toc = time.perf_counter()\n",
    "print(valaccu, \" orig time \", toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation curves\n",
    "fig, ax1 = plt.subplots(figsize=(16,9))\n",
    "color = 'tab:red'\n",
    "ax1.plot(range(len(loss_log)), loss_log, c=color, alpha=0.25, label=\"Train Loss\")\n",
    "ax1.plot([np.ceil((i+1)*len(train_data)/batch_size) for i in range(len(val_loss_log))], val_loss_log,c=\"red\", label=\"Val. Loss\")\n",
    "ax1.set_xlabel(\"Iterations\")\n",
    "ax1.set_ylabel(\"Avg. Cross-Entropy Loss\", c=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_ylim(-0.01,3)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.plot(range(len(acc_log)), acc_log, c=color, label=\"Train Acc.\", alpha=0.25)\n",
    "ax2.plot([np.ceil((i+1)*len(train_data)/batch_size) for i in range(len(val_acc_log))], val_acc_log,c=\"blue\", label=\"Val. Acc.\")\n",
    "ax2.set_ylabel(\" Accuracy\", c=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(-0.01,1.01)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "ax1.legend(loc=\"center\")\n",
    "ax2.legend(loc=\"center right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.perf_counter()\n",
    "valaccu = my_tester(dsmodel, testloader, len(test_data))\n",
    "toc = time.perf_counter()\n",
    "print(valaccu, \" orig time \", toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#student\n",
    "class SMSNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SMSNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1, stride=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(256)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        #TODO\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.pool1(self.conv2(x)))\n",
    "        #print(\"#####################3\", x.shape)\n",
    "        #x = self.relu3(self.pool2(self.conv3(x)))\n",
    "        nff = self.num_flat_features(x)\n",
    "        x = x.view(-1 , nff)\n",
    "        #print(x.shape, \"###########\")\n",
    "        x = self.batchnorm1(self.fc1(x))\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlab/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2747: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "2023-06-16 18:27:59 INFO     [Epoch   0]   Loss:    0.6194     Train Acc:     53.03%      Val Acc:      63.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:03 INFO     [Epoch   1]   Loss:    0.4593     Train Acc:     70.98%      Val Acc:     74.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:06 INFO     [Epoch   2]   Loss:    0.3952     Train Acc:     75.48%      Val Acc:      78.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:09 INFO     [Epoch   3]   Loss:    0.3613     Train Acc:     77.44%      Val Acc:     80.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:13 INFO     [Epoch   4]   Loss:    0.3358     Train Acc:     79.09%      Val Acc:     81.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:16 INFO     [Epoch   5]   Loss:    0.3208     Train Acc:     79.91%      Val Acc:     82.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:20 INFO     [Epoch   6]   Loss:    0.3105     Train Acc:     80.67%      Val Acc:     83.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:23 INFO     [Epoch   7]   Loss:    0.3028     Train Acc:     80.88%      Val Acc:      83.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:27 INFO     [Epoch   8]   Loss:     0.294     Train Acc:     81.61%      Val Acc:     83.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:30 INFO     [Epoch   9]   Loss:    0.2898     Train Acc:     81.69%      Val Acc:     84.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:34 INFO     [Epoch  10]   Loss:    0.2814     Train Acc:     82.23%      Val Acc:      84.0%\n",
      "2023-06-16 18:28:37 INFO     [Epoch  11]   Loss:    0.2778     Train Acc:     82.34%      Val Acc:      84.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:41 INFO     [Epoch  12]   Loss:    0.2712     Train Acc:      83.0%      Val Acc:     84.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:44 INFO     [Epoch  13]   Loss:    0.2664     Train Acc:     83.26%      Val Acc:      85.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:48 INFO     [Epoch  14]   Loss:    0.2613     Train Acc:     83.68%      Val Acc:      85.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:52 INFO     [Epoch  15]   Loss:    0.2536     Train Acc:     83.96%      Val Acc:      85.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:28:56 INFO     [Epoch  16]   Loss:     0.252     Train Acc:     84.34%      Val Acc:      85.6%\n",
      "2023-06-16 18:29:00 INFO     [Epoch  17]   Loss:    0.2471     Train Acc:     84.32%      Val Acc:     85.65%\n",
      "2023-06-16 18:29:04 INFO     [Epoch  18]   Loss:    0.2451     Train Acc:     84.49%      Val Acc:      86.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:29:08 INFO     [Epoch  19]   Loss:    0.2399     Train Acc:      84.8%      Val Acc:      86.1%\n",
      "2023-06-16 18:29:12 INFO     [Epoch  20]   Loss:    0.2366     Train Acc:     85.22%      Val Acc:     86.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:29:16 INFO     [Epoch  21]   Loss:     0.232     Train Acc:     85.59%      Val Acc:      86.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:29:20 INFO     [Epoch  22]   Loss:    0.2308     Train Acc:     85.56%      Val Acc:      86.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:29:24 INFO     [Epoch  23]   Loss:     0.225     Train Acc:     85.87%      Val Acc:     87.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:29:28 INFO     [Epoch  24]   Loss:    0.2264     Train Acc:     85.75%      Val Acc:     87.05%\n",
      "2023-06-16 18:29:32 INFO     [Epoch  25]   Loss:    0.2236     Train Acc:     85.88%      Val Acc:     87.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:29:36 INFO     [Epoch  26]   Loss:    0.2206     Train Acc:     85.98%      Val Acc:     87.25%\n",
      "2023-06-16 18:29:40 INFO     [Epoch  27]   Loss:    0.2163     Train Acc:     86.42%      Val Acc:      87.4%\n",
      "2023-06-16 18:29:44 INFO     [Epoch  28]   Loss:     0.216     Train Acc:     86.34%      Val Acc:      87.4%\n",
      "2023-06-16 18:29:49 INFO     [Epoch  29]   Loss:    0.2119     Train Acc:     86.35%      Val Acc:      87.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:29:53 INFO     [Epoch  30]   Loss:    0.2094     Train Acc:     86.83%      Val Acc:      87.8%\n",
      "2023-06-16 18:29:57 INFO     [Epoch  31]   Loss:    0.2071     Train Acc:     87.07%      Val Acc:      88.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:30:01 INFO     [Epoch  32]   Loss:     0.202     Train Acc:     87.44%      Val Acc:      88.0%\n",
      "2023-06-16 18:30:05 INFO     [Epoch  33]   Loss:    0.2036     Train Acc:     87.02%      Val Acc:     88.15%\n",
      "2023-06-16 18:30:09 INFO     [Epoch  34]   Loss:       0.2     Train Acc:     87.64%      Val Acc:      87.9%\n",
      "2023-06-16 18:30:13 INFO     [Epoch  35]   Loss:    0.1998     Train Acc:      87.5%      Val Acc:     87.65%\n",
      "2023-06-16 18:30:17 INFO     [Epoch  36]   Loss:    0.1972     Train Acc:     87.49%      Val Acc:     88.05%\n",
      "2023-06-16 18:30:21 INFO     [Epoch  37]   Loss:    0.1946     Train Acc:     87.96%      Val Acc:     88.15%\n",
      "2023-06-16 18:30:25 INFO     [Epoch  38]   Loss:    0.1931     Train Acc:     87.72%      Val Acc:      88.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:30:29 INFO     [Epoch  39]   Loss:    0.1888     Train Acc:     88.29%      Val Acc:     89.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:30:33 INFO     [Epoch  40]   Loss:    0.1911     Train Acc:     87.82%      Val Acc:     88.95%\n",
      "2023-06-16 18:30:37 INFO     [Epoch  41]   Loss:    0.1887     Train Acc:     88.44%      Val Acc:      88.9%\n",
      "2023-06-16 18:30:40 INFO     [Epoch  42]   Loss:     0.184     Train Acc:     88.57%      Val Acc:      88.9%\n",
      "2023-06-16 18:30:44 INFO     [Epoch  43]   Loss:    0.1888     Train Acc:     88.35%      Val Acc:      89.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:30:48 INFO     [Epoch  44]   Loss:    0.1862     Train Acc:     88.48%      Val Acc:     89.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:30:52 INFO     [Epoch  45]   Loss:    0.1823     Train Acc:     88.85%      Val Acc:     89.45%\n",
      "2023-06-16 18:30:55 INFO     [Epoch  46]   Loss:    0.1807     Train Acc:     88.49%      Val Acc:     89.25%\n",
      "2023-06-16 18:30:59 INFO     [Epoch  47]   Loss:    0.1803     Train Acc:     88.63%      Val Acc:      89.6%\n",
      "2023-06-16 18:31:02 INFO     [Epoch  48]   Loss:    0.1775     Train Acc:     89.05%      Val Acc:      90.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:31:06 INFO     [Epoch  49]   Loss:    0.1777     Train Acc:     88.98%      Val Acc:      90.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:31:09 INFO     [Epoch  50]   Loss:    0.1752     Train Acc:     89.05%      Val Acc:     89.75%\n",
      "2023-06-16 18:31:12 INFO     [Epoch  51]   Loss:    0.1738     Train Acc:     89.34%      Val Acc:      90.1%\n",
      "2023-06-16 18:31:16 INFO     [Epoch  52]   Loss:    0.1721     Train Acc:     89.26%      Val Acc:      89.8%\n",
      "2023-06-16 18:31:19 INFO     [Epoch  53]   Loss:    0.1718     Train Acc:      89.2%      Val Acc:     90.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:31:23 INFO     [Epoch  54]   Loss:    0.1695     Train Acc:     89.28%      Val Acc:      89.9%\n",
      "2023-06-16 18:31:26 INFO     [Epoch  55]   Loss:    0.1665     Train Acc:     89.73%      Val Acc:     90.05%\n",
      "2023-06-16 18:31:30 INFO     [Epoch  56]   Loss:    0.1692     Train Acc:     89.51%      Val Acc:      90.1%\n",
      "2023-06-16 18:31:33 INFO     [Epoch  57]   Loss:    0.1677     Train Acc:     89.93%      Val Acc:     90.05%\n",
      "2023-06-16 18:31:37 INFO     [Epoch  58]   Loss:    0.1661     Train Acc:     89.66%      Val Acc:     90.05%\n",
      "2023-06-16 18:31:40 INFO     [Epoch  59]   Loss:    0.1635     Train Acc:     89.88%      Val Acc:      90.2%\n",
      "2023-06-16 18:31:44 INFO     [Epoch  60]   Loss:    0.1636     Train Acc:     89.92%      Val Acc:      90.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:31:47 INFO     [Epoch  61]   Loss:     0.163     Train Acc:      89.7%      Val Acc:     91.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:31:51 INFO     [Epoch  62]   Loss:    0.1606     Train Acc:     90.12%      Val Acc:      90.8%\n",
      "2023-06-16 18:31:54 INFO     [Epoch  63]   Loss:    0.1601     Train Acc:     90.18%      Val Acc:      90.7%\n",
      "2023-06-16 18:31:58 INFO     [Epoch  64]   Loss:    0.1569     Train Acc:     90.22%      Val Acc:      90.6%\n",
      "2023-06-16 18:32:01 INFO     [Epoch  65]   Loss:    0.1588     Train Acc:     90.19%      Val Acc:     90.35%\n",
      "2023-06-16 18:32:04 INFO     [Epoch  66]   Loss:     0.157     Train Acc:     89.83%      Val Acc:      90.7%\n",
      "2023-06-16 18:32:08 INFO     [Epoch  67]   Loss:    0.1566     Train Acc:     90.21%      Val Acc:      90.5%\n",
      "2023-06-16 18:32:11 INFO     [Epoch  68]   Loss:    0.1567     Train Acc:     90.18%      Val Acc:     90.65%\n",
      "2023-06-16 18:32:14 INFO     [Epoch  69]   Loss:    0.1545     Train Acc:     90.23%      Val Acc:     90.75%\n",
      "2023-06-16 18:32:18 INFO     [Epoch  70]   Loss:    0.1546     Train Acc:     90.42%      Val Acc:     90.65%\n",
      "2023-06-16 18:32:22 INFO     [Epoch  71]   Loss:    0.1532     Train Acc:     90.58%      Val Acc:     91.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:32:26 INFO     [Epoch  72]   Loss:    0.1501     Train Acc:     90.88%      Val Acc:      91.0%\n",
      "2023-06-16 18:32:29 INFO     [Epoch  73]   Loss:    0.1506     Train Acc:      90.8%      Val Acc:      91.1%\n",
      "2023-06-16 18:32:33 INFO     [Epoch  74]   Loss:    0.1474     Train Acc:     90.97%      Val Acc:     90.95%\n",
      "2023-06-16 18:32:37 INFO     [Epoch  75]   Loss:    0.1496     Train Acc:      90.7%      Val Acc:      91.0%\n",
      "2023-06-16 18:32:40 INFO     [Epoch  76]   Loss:    0.1491     Train Acc:     90.75%      Val Acc:      90.8%\n",
      "2023-06-16 18:32:43 INFO     [Epoch  77]   Loss:    0.1497     Train Acc:     90.65%      Val Acc:      91.1%\n",
      "2023-06-16 18:32:47 INFO     [Epoch  78]   Loss:    0.1472     Train Acc:     91.06%      Val Acc:     90.95%\n",
      "2023-06-16 18:32:50 INFO     [Epoch  79]   Loss:     0.147     Train Acc:      91.0%      Val Acc:      91.0%\n",
      "2023-06-16 18:32:54 INFO     [Epoch  80]   Loss:    0.1457     Train Acc:     90.84%      Val Acc:      91.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:32:57 INFO     [Epoch  81]   Loss:    0.1464     Train Acc:     91.03%      Val Acc:      91.1%\n",
      "2023-06-16 18:33:01 INFO     [Epoch  82]   Loss:    0.1436     Train Acc:     91.14%      Val Acc:      91.3%\n",
      "2023-06-16 18:33:04 INFO     [Epoch  83]   Loss:    0.1422     Train Acc:     91.39%      Val Acc:      91.1%\n",
      "2023-06-16 18:33:07 INFO     [Epoch  84]   Loss:    0.1416     Train Acc:     91.23%      Val Acc:      91.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:33:11 INFO     [Epoch  85]   Loss:    0.1402     Train Acc:     91.56%      Val Acc:     91.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:33:14 INFO     [Epoch  86]   Loss:      0.14     Train Acc:     91.31%      Val Acc:      91.6%\n",
      "2023-06-16 18:33:18 INFO     [Epoch  87]   Loss:    0.1402     Train Acc:     91.42%      Val Acc:     91.55%\n",
      "2023-06-16 18:33:21 INFO     [Epoch  88]   Loss:    0.1392     Train Acc:     91.45%      Val Acc:     91.55%\n",
      "2023-06-16 18:33:25 INFO     [Epoch  89]   Loss:    0.1381     Train Acc:     91.33%      Val Acc:     91.35%\n",
      "2023-06-16 18:33:28 INFO     [Epoch  90]   Loss:    0.1384     Train Acc:     91.45%      Val Acc:     91.65%\n",
      "2023-06-16 18:33:32 INFO     [Epoch  91]   Loss:    0.1384     Train Acc:     91.42%      Val Acc:     91.55%\n",
      "2023-06-16 18:33:35 INFO     [Epoch  92]   Loss:    0.1361     Train Acc:      91.9%      Val Acc:     91.35%\n",
      "2023-06-16 18:33:39 INFO     [Epoch  93]   Loss:    0.1367     Train Acc:     91.52%      Val Acc:      92.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:33:43 INFO     [Epoch  94]   Loss:    0.1365     Train Acc:     91.44%      Val Acc:     92.05%\n",
      "2023-06-16 18:33:46 INFO     [Epoch  95]   Loss:    0.1353     Train Acc:     91.73%      Val Acc:     92.15%\n",
      "2023-06-16 18:33:49 INFO     [Epoch  96]   Loss:    0.1324     Train Acc:     91.99%      Val Acc:      91.6%\n",
      "2023-06-16 18:33:53 INFO     [Epoch  97]   Loss:    0.1317     Train Acc:     92.24%      Val Acc:      92.0%\n",
      "2023-06-16 18:33:56 INFO     [Epoch  98]   Loss:    0.1312     Train Acc:     91.95%      Val Acc:      91.8%\n",
      "2023-06-16 18:34:00 INFO     [Epoch  99]   Loss:    0.1332     Train Acc:     91.68%      Val Acc:     91.85%\n",
      "2023-06-16 18:34:04 INFO     [Epoch 100]   Loss:    0.1331     Train Acc:     92.05%      Val Acc:      92.0%\n",
      "2023-06-16 18:34:08 INFO     [Epoch 101]   Loss:     0.128     Train Acc:     92.19%      Val Acc:      92.0%\n",
      "2023-06-16 18:34:12 INFO     [Epoch 102]   Loss:    0.1307     Train Acc:     91.95%      Val Acc:      91.9%\n",
      "2023-06-16 18:34:16 INFO     [Epoch 103]   Loss:    0.1299     Train Acc:     92.17%      Val Acc:      91.7%\n",
      "2023-06-16 18:34:20 INFO     [Epoch 104]   Loss:    0.1277     Train Acc:     92.23%      Val Acc:      91.8%\n",
      "2023-06-16 18:34:23 INFO     [Epoch 105]   Loss:    0.1286     Train Acc:     92.02%      Val Acc:     91.75%\n",
      "2023-06-16 18:34:27 INFO     [Epoch 106]   Loss:     0.128     Train Acc:     92.16%      Val Acc:      92.2%\n",
      "2023-06-16 18:34:30 INFO     [Epoch 107]   Loss:    0.1275     Train Acc:     92.44%      Val Acc:      91.5%\n",
      "2023-06-16 18:34:34 INFO     [Epoch 108]   Loss:     0.127     Train Acc:     92.27%      Val Acc:      92.2%\n",
      "2023-06-16 18:34:37 INFO     [Epoch 109]   Loss:    0.1285     Train Acc:     92.05%      Val Acc:      91.9%\n",
      "2023-06-16 18:34:41 INFO     [Epoch 110]   Loss:    0.1246     Train Acc:     92.51%      Val Acc:     92.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:34:44 INFO     [Epoch 111]   Loss:    0.1245     Train Acc:     92.62%      Val Acc:      92.2%\n",
      "2023-06-16 18:34:48 INFO     [Epoch 112]   Loss:    0.1268     Train Acc:     92.18%      Val Acc:     92.25%\n",
      "2023-06-16 18:34:51 INFO     [Epoch 113]   Loss:    0.1238     Train Acc:     92.48%      Val Acc:     92.25%\n",
      "2023-06-16 18:34:55 INFO     [Epoch 114]   Loss:    0.1255     Train Acc:     92.31%      Val Acc:      92.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:34:59 INFO     [Epoch 115]   Loss:    0.1244     Train Acc:     92.66%      Val Acc:     92.15%\n",
      "2023-06-16 18:35:03 INFO     [Epoch 116]   Loss:     0.124     Train Acc:     92.54%      Val Acc:     91.85%\n",
      "2023-06-16 18:35:06 INFO     [Epoch 117]   Loss:    0.1205     Train Acc:     92.81%      Val Acc:     92.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:35:10 INFO     [Epoch 118]   Loss:    0.1213     Train Acc:     92.84%      Val Acc:     92.65%\n",
      "2023-06-16 18:35:14 INFO     [Epoch 119]   Loss:    0.1201     Train Acc:      92.6%      Val Acc:     92.45%\n",
      "2023-06-16 18:35:17 INFO     [Epoch 120]   Loss:    0.1195     Train Acc:     92.76%      Val Acc:      92.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:35:21 INFO     [Epoch 121]   Loss:    0.1223     Train Acc:     93.02%      Val Acc:     92.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:35:25 INFO     [Epoch 122]   Loss:    0.1188     Train Acc:     92.68%      Val Acc:     92.25%\n",
      "2023-06-16 18:35:30 INFO     [Epoch 123]   Loss:     0.118     Train Acc:     93.09%      Val Acc:      92.3%\n",
      "2023-06-16 18:35:33 INFO     [Epoch 124]   Loss:    0.1188     Train Acc:     92.94%      Val Acc:      92.5%\n",
      "2023-06-16 18:35:37 INFO     [Epoch 125]   Loss:    0.1204     Train Acc:     92.54%      Val Acc:     92.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:35:41 INFO     [Epoch 126]   Loss:     0.116     Train Acc:     93.01%      Val Acc:      92.7%\n",
      "2023-06-16 18:35:44 INFO     [Epoch 127]   Loss:    0.1199     Train Acc:     92.71%      Val Acc:      92.3%\n",
      "2023-06-16 18:35:48 INFO     [Epoch 128]   Loss:    0.1187     Train Acc:     92.95%      Val Acc:     92.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:35:51 INFO     [Epoch 129]   Loss:     0.117     Train Acc:      93.0%      Val Acc:      92.9%\n",
      "2023-06-16 18:35:55 INFO     [Epoch 130]   Loss:    0.1161     Train Acc:     92.98%      Val Acc:     92.85%\n",
      "2023-06-16 18:35:58 INFO     [Epoch 131]   Loss:    0.1185     Train Acc:     92.71%      Val Acc:      93.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:36:02 INFO     [Epoch 132]   Loss:    0.1164     Train Acc:     93.05%      Val Acc:     92.65%\n",
      "2023-06-16 18:36:05 INFO     [Epoch 133]   Loss:    0.1149     Train Acc:     93.14%      Val Acc:      92.8%\n",
      "2023-06-16 18:36:09 INFO     [Epoch 134]   Loss:    0.1142     Train Acc:     93.52%      Val Acc:      92.6%\n",
      "2023-06-16 18:36:12 INFO     [Epoch 135]   Loss:    0.1146     Train Acc:     93.42%      Val Acc:     92.45%\n",
      "2023-06-16 18:36:17 INFO     [Epoch 136]   Loss:    0.1132     Train Acc:     93.36%      Val Acc:      92.1%\n",
      "2023-06-16 18:36:21 INFO     [Epoch 137]   Loss:    0.1142     Train Acc:     93.18%      Val Acc:     92.75%\n",
      "2023-06-16 18:36:25 INFO     [Epoch 138]   Loss:    0.1108     Train Acc:     93.52%      Val Acc:      92.6%\n",
      "2023-06-16 18:36:29 INFO     [Epoch 139]   Loss:    0.1124     Train Acc:     93.23%      Val Acc:      92.8%\n",
      "2023-06-16 18:36:33 INFO     [Epoch 140]   Loss:    0.1102     Train Acc:     93.56%      Val Acc:      92.2%\n",
      "2023-06-16 18:36:37 INFO     [Epoch 141]   Loss:    0.1108     Train Acc:     93.48%      Val Acc:      92.3%\n",
      "2023-06-16 18:36:41 INFO     [Epoch 142]   Loss:     0.111     Train Acc:     93.42%      Val Acc:      92.8%\n",
      "2023-06-16 18:36:45 INFO     [Epoch 143]   Loss:    0.1113     Train Acc:     93.35%      Val Acc:     92.75%\n",
      "2023-06-16 18:36:49 INFO     [Epoch 144]   Loss:    0.1117     Train Acc:     93.42%      Val Acc:     92.95%\n",
      "2023-06-16 18:36:53 INFO     [Epoch 145]   Loss:    0.1105     Train Acc:     93.41%      Val Acc:      92.6%\n",
      "2023-06-16 18:36:57 INFO     [Epoch 146]   Loss:    0.1108     Train Acc:      93.6%      Val Acc:     92.95%\n",
      "2023-06-16 18:37:01 INFO     [Epoch 147]   Loss:    0.1094     Train Acc:     93.65%      Val Acc:     91.95%\n",
      "2023-06-16 18:37:04 INFO     [Epoch 148]   Loss:    0.1103     Train Acc:     93.52%      Val Acc:     93.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 18:37:08 INFO     [Epoch 149]   Loss:    0.1099     Train Acc:     93.58%      Val Acc:      93.0%\n"
     ]
    }
   ],
   "source": [
    "#trainiing smaller distilled student \n",
    "# Build model\n",
    "#editing\n",
    "smsmodel = SMSNet()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "steacher_model = SNet()\n",
    "tsmodel_dict = torch.load(home+'/outputs/distil_prune.pth')\n",
    "steacher_model.load_state_dict(tsmodel_dict['model_state_dict'])\n",
    "steacher_model.eval()\n",
    "# Main training loop\n",
    "optimizer = torch.optim.Adam(smsmodel.parameters(), lr=1e-4, weight_decay=0.001)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "dsmodel.to(device)\n",
    "loss_log = []\n",
    "acc_log = []\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "best_val_acc = 0.0\n",
    "for i in range(150):\n",
    "\n",
    "  # Run an epoch of training\n",
    "  train_running_loss = 0\n",
    "  train_running_acc = 0\n",
    "  smsmodel.train()\n",
    "  for j,input in enumerate(trainloader,0):\n",
    "   \n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "    out = smsmodel(x)\n",
    "    targets = steacher_model(x)\n",
    "    #loss = my_loss(out, targets)\n",
    "    #loss = criterion(out, targets)\n",
    "    loss = loss_kd(out, y, targets)\n",
    "\n",
    "    smsmodel.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    train_running_loss += loss.item()\n",
    "    train_running_acc += correct.item()\n",
    "    loss_log.append(loss.item())\n",
    "    acc_log.append(correct.item()/len(y))\n",
    "\n",
    "  train_running_loss /= j\n",
    "  train_running_acc /= len(train_data)\n",
    "\n",
    "  # Evaluate on validation\n",
    "  val_acc = 0\n",
    "  val_loss = 0\n",
    "  smsmodel.eval()\n",
    "  for j,input in enumerate(valloader,0):\n",
    "\n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "    \n",
    "    out = smsmodel(x)\n",
    "    #targets = teacher_model(x)\n",
    "    loss2 = criterion(out, y)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    val_acc += correct.item()\n",
    "    val_loss += loss2.item()\n",
    "\n",
    "  val_acc /= len(val_data)\n",
    "  val_loss /= j\n",
    "  if val_acc > best_val_acc:\n",
    "    best_val_acc = val_acc\n",
    "    print(\"saving model\")\n",
    "    torch.save({\n",
    "                'epoch': i+1,\n",
    "                'model_state_dict': dsmodel.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, home+'/outputs/nested_distil.pth')\n",
    "    \n",
    "  val_acc_log.append(val_acc)\n",
    "\n",
    "  val_loss_log.append(val_loss)\n",
    "\n",
    "  logging.info(\"[Epoch {:3}]   Loss:  {:8.4}     Train Acc:  {:8.4}%      Val Acc:  {:8.4}%\".format(i,train_running_loss, train_running_acc*100,val_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133019\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in smsmodel.parameters())\n",
    "print(pytorch_total_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
