{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import logging\n",
    "import pickle\n",
    "from os.path import expanduser\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torchvision import transforms, datasets\n",
    "# Imports for plotting our resu\n",
    "home = expanduser(\"~/Model_compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.quantization\n",
    "from torch.quantization import QuantStub, DeQuantStub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR3(Dataset):\n",
    "\n",
    "    def __init__(self,split=\"train\",transform=None):\n",
    "      if split==\"train\":\n",
    "        with open(\"cifar10_hst_train\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo) \n",
    "      elif split==\"val\":\n",
    "        with open(\"cifar10_hst_val\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo)\n",
    "      else:\n",
    "        with open(\"cifar10_hst_test\", 'rb') as fo:\n",
    "          self.data = pickle.load(fo)\n",
    "      \n",
    "      self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['labels'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.data['images'][idx,:]\n",
    "        r = x[:1024].reshape(32,32)\n",
    "        g = x[1024:2048].reshape(32,32)\n",
    "        b = x[2048:].reshape(32,32)\n",
    "        \n",
    "        x = Tensor(np.stack([r,g,b]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "          x = self.transform(x)\n",
    "        \n",
    "        y = self.data['labels'][idx,0]\n",
    "        return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean=[127.5, 127.5, 127.5],\n",
    "                             std=[127.5, 127.5, 127.5])\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[127.5, 127.5, 127.5],\n",
    "                             std=[127.5, 127.5, 127.5])\n",
    "    ])\n",
    "\n",
    "train_data = CIFAR3(\"train\", transform=train_transform)\n",
    "val_data = CIFAR3(\"val\", transform=test_transform)\n",
    "test_data = CIFAR3(\"test\", transform=test_transform)\n",
    "\n",
    "batch_size = 256\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(quantized_model, model):\n",
    "    \"\"\" Loads in the weights into an object meant for quantization \"\"\"\n",
    "    state_dict = model.state_dict()\n",
    "    model = model.to('cpu')\n",
    "    quantized_model.load_state_dict(state_dict)\n",
    "\n",
    "def fuse_modules(model):\n",
    "    \"\"\" Fuse together convolutions/linear layers and ReLU \"\"\"\n",
    "    torch.quantization.fuse_modules(model, [['conv1', 'relu1'], \n",
    "                                            ['conv2', 'relu2'],\n",
    "                                            ['conv3', 'relu3'],\n",
    "                                            ['conv4', 'relu4'],\n",
    "                                            ['fc1', 'relu5']], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, q = False):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.fc1 = nn.Linear(4096, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.q = q\n",
    "        if q:\n",
    "          self.quant = QuantStub()\n",
    "          self.dequant = DeQuantStub()\n",
    "       \n",
    "    def forward(self, x):\n",
    "        #TODO\n",
    "        if self.q:\n",
    "            x = self.quant(x)\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.pool1(self.conv2(x)))\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = self.relu4(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = torch.reshape(x, (-1 , 4096))\n",
    "        #x = self.batchnorm1(self.fc1(x))\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc2(x)\n",
    "        if self.q:\n",
    "          x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): ReLU()\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (relu5): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "model = Net(q=True)\n",
    "# model_dict = torch.load(home+'/outputs/quant_model.pth')\n",
    "# model.load_state_dict(model_dict['model_state_dict'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tester(model, valloader, length):\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    device = 'cpu'\n",
    "    for j,input in enumerate(valloader,0):\n",
    "\n",
    "        x = input[0].to(device)\n",
    "        y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "        \n",
    "        out = model(x)\n",
    "\n",
    "        loss = criterion(out,y)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct = (predicted == y).sum()\n",
    "\n",
    "        val_acc += correct.item()\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    val_acc /= length\n",
    "    val_loss /= j\n",
    "    return val_acc*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:11:07 INFO     [Epoch   0]   Loss:     1.116     Train Acc:      42.4%      Val Acc:     49.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:11:21 INFO     [Epoch   1]   Loss:     1.095     Train Acc:     52.79%      Val Acc:      61.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:11:35 INFO     [Epoch   2]   Loss:     1.035     Train Acc:     62.67%      Val Acc:     61.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:11:52 INFO     [Epoch   3]   Loss:    0.9259     Train Acc:     62.76%      Val Acc:      62.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:12:10 INFO     [Epoch   4]   Loss:    0.8394     Train Acc:     63.91%      Val Acc:     64.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:12:27 INFO     [Epoch   5]   Loss:    0.7868     Train Acc:      66.1%      Val Acc:     66.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:12:42 INFO     [Epoch   6]   Loss:    0.7504     Train Acc:     68.28%      Val Acc:     68.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:12:58 INFO     [Epoch   7]   Loss:    0.7255     Train Acc:     69.38%      Val Acc:     69.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:13:13 INFO     [Epoch   8]   Loss:    0.7095     Train Acc:     70.25%      Val Acc:      70.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:13:29 INFO     [Epoch   9]   Loss:     0.688     Train Acc:     71.56%      Val Acc:      72.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:13:46 INFO     [Epoch  10]   Loss:    0.6756     Train Acc:     72.28%      Val Acc:      73.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:14:02 INFO     [Epoch  11]   Loss:    0.6635     Train Acc:     73.08%      Val Acc:     74.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:14:17 INFO     [Epoch  12]   Loss:    0.6525     Train Acc:     73.52%      Val Acc:      73.7%\n",
      "2023-06-16 20:14:32 INFO     [Epoch  13]   Loss:    0.6431     Train Acc:     74.35%      Val Acc:     74.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:14:48 INFO     [Epoch  14]   Loss:    0.6345     Train Acc:     74.56%      Val Acc:     76.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:15:04 INFO     [Epoch  15]   Loss:    0.6247     Train Acc:     75.55%      Val Acc:     76.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:15:21 INFO     [Epoch  16]   Loss:    0.6163     Train Acc:     75.75%      Val Acc:     77.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:15:38 INFO     [Epoch  17]   Loss:     0.608     Train Acc:     76.06%      Val Acc:      77.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:15:54 INFO     [Epoch  18]   Loss:    0.5989     Train Acc:     76.75%      Val Acc:     78.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:16:09 INFO     [Epoch  19]   Loss:    0.5915     Train Acc:     76.95%      Val Acc:     78.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:16:26 INFO     [Epoch  20]   Loss:    0.5841     Train Acc:     77.07%      Val Acc:      78.4%\n",
      "2023-06-16 20:16:41 INFO     [Epoch  21]   Loss:    0.5796     Train Acc:      77.5%      Val Acc:     79.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:16:56 INFO     [Epoch  22]   Loss:    0.5745     Train Acc:     77.57%      Val Acc:     79.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:17:11 INFO     [Epoch  23]   Loss:    0.5631     Train Acc:     78.28%      Val Acc:      80.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:17:27 INFO     [Epoch  24]   Loss:    0.5587     Train Acc:     78.68%      Val Acc:     80.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:17:44 INFO     [Epoch  25]   Loss:    0.5531     Train Acc:     78.67%      Val Acc:      81.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:17:58 INFO     [Epoch  26]   Loss:    0.5496     Train Acc:     78.75%      Val Acc:     80.55%\n",
      "2023-06-16 20:18:12 INFO     [Epoch  27]   Loss:    0.5437     Train Acc:     78.86%      Val Acc:      80.8%\n",
      "2023-06-16 20:18:27 INFO     [Epoch  28]   Loss:    0.5401     Train Acc:     79.36%      Val Acc:     81.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:18:42 INFO     [Epoch  29]   Loss:    0.5358     Train Acc:     79.37%      Val Acc:      81.1%\n",
      "2023-06-16 20:18:59 INFO     [Epoch  30]   Loss:      0.53     Train Acc:     79.74%      Val Acc:     81.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:19:15 INFO     [Epoch  31]   Loss:    0.5294     Train Acc:     79.55%      Val Acc:      81.4%\n",
      "2023-06-16 20:19:32 INFO     [Epoch  32]   Loss:    0.5224     Train Acc:     80.12%      Val Acc:     81.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:19:48 INFO     [Epoch  33]   Loss:    0.5205     Train Acc:     79.87%      Val Acc:     81.45%\n",
      "2023-06-16 20:20:06 INFO     [Epoch  34]   Loss:    0.5182     Train Acc:     79.86%      Val Acc:     81.45%\n",
      "2023-06-16 20:20:20 INFO     [Epoch  35]   Loss:    0.5129     Train Acc:      80.1%      Val Acc:      81.7%\n",
      "2023-06-16 20:20:35 INFO     [Epoch  36]   Loss:    0.5114     Train Acc:     80.28%      Val Acc:      81.9%\n",
      "2023-06-16 20:20:51 INFO     [Epoch  37]   Loss:    0.5081     Train Acc:     80.89%      Val Acc:     81.95%\n",
      "2023-06-16 20:21:07 INFO     [Epoch  38]   Loss:    0.5039     Train Acc:     80.51%      Val Acc:     82.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:21:22 INFO     [Epoch  39]   Loss:    0.5047     Train Acc:     80.64%      Val Acc:     82.25%\n",
      "2023-06-16 20:21:37 INFO     [Epoch  40]   Loss:    0.5021     Train Acc:     80.85%      Val Acc:     82.25%\n",
      "2023-06-16 20:21:52 INFO     [Epoch  41]   Loss:     0.497     Train Acc:      81.0%      Val Acc:     82.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:22:09 INFO     [Epoch  42]   Loss:     0.494     Train Acc:     80.98%      Val Acc:      83.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:22:24 INFO     [Epoch  43]   Loss:    0.4886     Train Acc:     81.51%      Val Acc:      82.4%\n",
      "2023-06-16 20:22:41 INFO     [Epoch  44]   Loss:    0.4878     Train Acc:     81.13%      Val Acc:     82.45%\n",
      "2023-06-16 20:22:58 INFO     [Epoch  45]   Loss:    0.4853     Train Acc:     81.32%      Val Acc:     82.35%\n",
      "2023-06-16 20:23:14 INFO     [Epoch  46]   Loss:    0.4851     Train Acc:     81.88%      Val Acc:     82.15%\n",
      "2023-06-16 20:23:30 INFO     [Epoch  47]   Loss:    0.4824     Train Acc:     81.55%      Val Acc:      82.6%\n",
      "2023-06-16 20:23:44 INFO     [Epoch  48]   Loss:    0.4822     Train Acc:     81.44%      Val Acc:     83.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 20:24:00 INFO     [Epoch  49]   Loss:    0.4775     Train Acc:     81.69%      Val Acc:      82.8%\n"
     ]
    }
   ],
   "source": [
    "loss_log = []\n",
    "acc_log = []\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "best_val_acc = 0.0\n",
    "for i in range(50):\n",
    "\n",
    "  # Run an epoch of training\n",
    "  train_running_loss = 0\n",
    "  train_running_acc = 0\n",
    "  model.train()\n",
    "  for j,input in enumerate(trainloader,0):\n",
    "   \n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "    out = model(x)\n",
    "    loss = criterion(out,y)\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    train_running_loss += loss.item()\n",
    "    train_running_acc += correct.item()\n",
    "    loss_log.append(loss.item())\n",
    "    acc_log.append(correct.item()/len(y))\n",
    "\n",
    "  train_running_loss /= j\n",
    "  train_running_acc /= len(train_data)\n",
    "\n",
    "  # Evaluate on validation\n",
    "  val_acc = 0\n",
    "  val_loss = 0\n",
    "  model.eval()\n",
    "  for j,input in enumerate(valloader,0):\n",
    "\n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "    \n",
    "    out = model(x)\n",
    "\n",
    "    loss = criterion(out,y)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    val_acc += correct.item()\n",
    "    val_loss += loss.item()\n",
    "\n",
    "  val_acc /= len(val_data)\n",
    "  val_loss /= j\n",
    "  if val_acc > best_val_acc:\n",
    "    best_val_acc = val_acc\n",
    "    print(\"saving model\")\n",
    "    torch.save({\n",
    "                'epoch': i+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, home+'/outputs/quant.pth')\n",
    "    \n",
    "  val_acc_log.append(val_acc)\n",
    "\n",
    "  val_loss_log.append(val_loss)\n",
    "  logging.info(\"[Epoch {:3}]   Loss:  {:8.4}     Train Acc:  {:8.4}%      Val Acc:  {:8.4}%\".format(i,train_running_loss, train_running_acc*100,val_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2164771\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet = Net(q=True)\n",
    "load_model(qnet, model)\n",
    "fuse_modules(qnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.33333333333333 1.3451600074768066\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "valaccu = my_tester(qnet, testloader, len(test_data))\n",
    "tac = time.time()\n",
    "print(valaccu, tac-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet.qconfig = torch.quantization.default_qconfig\n",
    "print(qnet.qconfig)\n",
    "torch.quantization.prepare(qnet, inplace=True)\n",
    "print('Post Training Quantization Prepare: Inserting Observers')\n",
    "print('\\n Conv1: After observer insertion \\n\\n', qnet.conv1)\n",
    "\n",
    "my_tester(qnet, trainloader, len(train_data))\n",
    "print('Post Training Quantization: Calibration done')\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "print('Post Training Quantization: Convert done')\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valaccu = my_tester(qnet, testloader, len(test_data))\n",
    "print(valaccu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet = Net(q=True)\n",
    "load_model(qnet, model)\n",
    "fuse_modules(qnet)\n",
    "qnet.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "print(qnet.qconfig)\n",
    "\n",
    "torch.quantization.prepare(qnet, inplace=True)\n",
    "va = my_tester(qnet, trainloader, len(train_data))\n",
    "torch.quantization.convert(qnet, inplace=True)\n",
    "valaccu = my_tester(qnet, testloader, len(test_data))\n",
    "print(valaccu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "                'epoch': 50,\n",
    "                'model_state_dict': qnet.state_dict(),\n",
    "                }, home+'/outputs/quant_model.pth')\n",
    "torch.save({\n",
    "                'epoch': 50,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                }, home+'/outputs/comparison_model.pth')\n",
    "\n",
    "#8 MB vs 2 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Conv1: After fusion and quantization \n",
      "\n",
      " ConvReLU2d(\n",
      "  3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "  (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
      "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
      "    (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
      "  )\n",
      "  (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
      "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
      "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): ConvReLU2d(\n",
       "    3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu1): Identity()\n",
       "  (conv2): ConvReLU2d(\n",
       "    32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2): Identity()\n",
       "  (conv3): ConvReLU2d(\n",
       "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu3): Identity()\n",
       "  (conv4): ConvReLU2d(\n",
       "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu4): Identity()\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): LinearReLU(\n",
       "    in_features=4096, out_features=512, bias=True\n",
       "    (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (relu5): Identity()\n",
       "  (fc2): Linear(\n",
       "    in_features=512, out_features=3, bias=True\n",
       "    (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "      (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantization aware training\n",
    "qnet = Net(q=True)\n",
    "fuse_modules(qnet)\n",
    "qnet.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "torch.quantization.prepare_qat(qnet, inplace=True)\n",
    "\n",
    "print('\\n Conv1: After fusion and quantization \\n\\n', qnet.conv1)\n",
    "optimizer = torch.optim.Adam(qnet.parameters(), lr=1e-5, weight_decay=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "qnet.to(device)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:49:50 INFO     [Epoch   0]   Loss:     1.116     Train Acc:      43.8%      Val Acc:     60.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:50:15 INFO     [Epoch   1]   Loss:     1.104     Train Acc:     62.88%      Val Acc:      66.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:50:40 INFO     [Epoch   2]   Loss:     1.083     Train Acc:     65.94%      Val Acc:     68.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:51:04 INFO     [Epoch   3]   Loss:     1.044     Train Acc:     67.34%      Val Acc:     68.45%\n",
      "2023-06-11 18:51:27 INFO     [Epoch   4]   Loss:    0.9802     Train Acc:     68.91%      Val Acc:     69.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:51:51 INFO     [Epoch   5]   Loss:     0.896     Train Acc:     69.28%      Val Acc:      69.3%\n",
      "2023-06-11 18:52:17 INFO     [Epoch   6]   Loss:    0.8069     Train Acc:      70.1%      Val Acc:     70.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:52:43 INFO     [Epoch   7]   Loss:    0.7359     Train Acc:      71.2%      Val Acc:      72.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:53:07 INFO     [Epoch   8]   Loss:    0.6947     Train Acc:     71.84%      Val Acc:     72.25%\n",
      "2023-06-11 18:53:33 INFO     [Epoch   9]   Loss:    0.6716     Train Acc:     72.55%      Val Acc:      73.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:53:58 INFO     [Epoch  10]   Loss:    0.6534     Train Acc:     73.67%      Val Acc:      75.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:54:23 INFO     [Epoch  11]   Loss:    0.6416     Train Acc:     73.83%      Val Acc:     76.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:54:48 INFO     [Epoch  12]   Loss:    0.6303     Train Acc:     74.72%      Val Acc:     75.95%\n",
      "2023-06-11 18:55:14 INFO     [Epoch  13]   Loss:    0.6223     Train Acc:     75.02%      Val Acc:     76.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:55:39 INFO     [Epoch  14]   Loss:    0.6141     Train Acc:     75.61%      Val Acc:     75.85%\n",
      "2023-06-11 18:56:04 INFO     [Epoch  15]   Loss:    0.6056     Train Acc:     75.88%      Val Acc:      77.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:56:30 INFO     [Epoch  16]   Loss:    0.5972     Train Acc:     76.35%      Val Acc:     77.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:56:55 INFO     [Epoch  17]   Loss:    0.5908     Train Acc:     76.69%      Val Acc:      78.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:57:21 INFO     [Epoch  18]   Loss:    0.5847     Train Acc:     76.81%      Val Acc:     78.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:57:47 INFO     [Epoch  19]   Loss:    0.5766     Train Acc:     77.11%      Val Acc:      79.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:58:14 INFO     [Epoch  20]   Loss:    0.5721     Train Acc:     77.38%      Val Acc:     79.15%\n",
      "2023-06-11 18:58:40 INFO     [Epoch  21]   Loss:    0.5622     Train Acc:     77.84%      Val Acc:      79.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:59:06 INFO     [Epoch  22]   Loss:    0.5591     Train Acc:     77.59%      Val Acc:     80.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:59:32 INFO     [Epoch  23]   Loss:    0.5516     Train Acc:     78.37%      Val Acc:      80.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 18:59:58 INFO     [Epoch  24]   Loss:    0.5466     Train Acc:     78.52%      Val Acc:      80.7%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 19:00:25 INFO     [Epoch  25]   Loss:    0.5418     Train Acc:     78.64%      Val Acc:      80.3%\n",
      "2023-06-11 19:00:51 INFO     [Epoch  26]   Loss:    0.5407     Train Acc:     78.65%      Val Acc:     81.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 19:01:16 INFO     [Epoch  27]   Loss:    0.5358     Train Acc:     78.72%      Val Acc:     80.35%\n",
      "2023-06-11 19:01:41 INFO     [Epoch  28]   Loss:    0.5348     Train Acc:     78.76%      Val Acc:      80.6%\n",
      "2023-06-11 19:02:05 INFO     [Epoch  29]   Loss:    0.5307     Train Acc:     79.18%      Val Acc:      81.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 19:02:29 INFO     [Epoch  30]   Loss:    0.5226     Train Acc:     79.53%      Val Acc:      81.4%\n",
      "2023-06-11 19:02:54 INFO     [Epoch  31]   Loss:    0.5209     Train Acc:     79.62%      Val Acc:     81.45%\n",
      "2023-06-11 19:03:18 INFO     [Epoch  32]   Loss:    0.5181     Train Acc:     80.01%      Val Acc:      82.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 19:03:44 INFO     [Epoch  33]   Loss:    0.5155     Train Acc:     79.85%      Val Acc:     81.45%\n",
      "2023-06-11 19:04:08 INFO     [Epoch  34]   Loss:    0.5147     Train Acc:     79.78%      Val Acc:      81.8%\n",
      "2023-06-11 19:04:30 INFO     [Epoch  35]   Loss:    0.5099     Train Acc:     80.38%      Val Acc:      81.6%\n",
      "2023-06-11 19:04:54 INFO     [Epoch  36]   Loss:    0.5088     Train Acc:     80.38%      Val Acc:      81.5%\n",
      "2023-06-11 19:05:18 INFO     [Epoch  37]   Loss:    0.5075     Train Acc:     80.45%      Val Acc:      82.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 19:05:43 INFO     [Epoch  38]   Loss:    0.5034     Train Acc:     80.51%      Val Acc:      82.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 19:06:09 INFO     [Epoch  39]   Loss:    0.5007     Train Acc:     80.53%      Val Acc:      82.2%\n",
      "2023-06-11 19:06:32 INFO     [Epoch  40]   Loss:    0.5022     Train Acc:     80.62%      Val Acc:     81.85%\n",
      "2023-06-11 19:06:55 INFO     [Epoch  41]   Loss:    0.4969     Train Acc:     81.02%      Val Acc:      82.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 19:07:18 INFO     [Epoch  42]   Loss:    0.4978     Train Acc:     80.54%      Val Acc:      82.1%\n",
      "2023-06-11 19:07:41 INFO     [Epoch  43]   Loss:    0.4928     Train Acc:     81.06%      Val Acc:      82.2%\n",
      "2023-06-11 19:08:06 INFO     [Epoch  44]   Loss:    0.4907     Train Acc:     80.95%      Val Acc:      81.9%\n",
      "2023-06-11 19:08:31 INFO     [Epoch  45]   Loss:    0.4932     Train Acc:     81.15%      Val Acc:      82.5%\n",
      "2023-06-11 19:08:54 INFO     [Epoch  46]   Loss:    0.4878     Train Acc:     81.05%      Val Acc:     82.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 19:09:20 INFO     [Epoch  47]   Loss:     0.484     Train Acc:      81.2%      Val Acc:      82.7%\n",
      "2023-06-11 19:09:45 INFO     [Epoch  48]   Loss:    0.4832     Train Acc:     81.55%      Val Acc:      82.7%\n",
      "2023-06-11 19:10:07 INFO     [Epoch  49]   Loss:    0.4821     Train Acc:     81.41%      Val Acc:      83.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    }
   ],
   "source": [
    "loss_log = []\n",
    "acc_log = []\n",
    "val_acc_log = []\n",
    "val_loss_log = []\n",
    "best_val_acc = 0.0\n",
    "for i in range(50):\n",
    "\n",
    "  # Run an epoch of training\n",
    "  train_running_loss = 0\n",
    "  train_running_acc = 0\n",
    "  qnet.train()\n",
    "  for j,input in enumerate(trainloader,0):\n",
    "   \n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "    out = qnet(x)\n",
    "    loss = criterion(out,y)\n",
    "\n",
    "    qnet.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    train_running_loss += loss.item()\n",
    "    train_running_acc += correct.item()\n",
    "    loss_log.append(loss.item())\n",
    "    acc_log.append(correct.item()/len(y))\n",
    "\n",
    "  train_running_loss /= j\n",
    "  train_running_acc /= len(train_data)\n",
    "\n",
    "  # Evaluate on validation\n",
    "  val_acc = 0\n",
    "  val_loss = 0\n",
    "  qnet.eval()\n",
    "  for j,input in enumerate(valloader,0):\n",
    "\n",
    "    x = input[0].to(device)\n",
    "    y = input[1].type(torch.LongTensor).to(device)\n",
    "\n",
    "    \n",
    "    out = qnet(x)\n",
    "\n",
    "    loss = criterion(out,y)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    correct = (predicted == y).sum()\n",
    "\n",
    "    val_acc += correct.item()\n",
    "    val_loss += loss.item()\n",
    "\n",
    "  val_acc /= len(val_data)\n",
    "  val_loss /= j\n",
    "  if val_acc > best_val_acc:\n",
    "    best_val_acc = val_acc\n",
    "    print(\"saving model\")\n",
    "    torch.save({\n",
    "                'epoch': i+1,\n",
    "                'model_state_dict': qnet.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, home+'/outputs/qat.pth')\n",
    "    \n",
    "  val_acc_log.append(val_acc)\n",
    "\n",
    "  val_loss_log.append(val_loss)\n",
    "  logging.info(\"[Epoch {:3}]   Loss:  {:8.4}     Train Acc:  {:8.4}%      Val Acc:  {:8.4}%\".format(i,train_running_loss, train_running_acc*100,val_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.13333333333334  orig time  1.759534425997117\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.perf_counter()\n",
    "valaccu = my_tester(qnet, testloader, len(test_data))\n",
    "toc = time.perf_counter()\n",
    "print(valaccu, \" orig time \", toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize it without calibration (weights will not be final)\n",
    "#modell.train()\n",
    "# model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "# #model_fp32_fused = torch.quantization.fuse_modules(model,[['conv1', 'bn1', 'relu']])\n",
    "# model_fp32_prepared = torch.quantization.prepare_qat(modell)\n",
    "# model_int8 = torch.quantization.convert(model_fp32_prepared)\n",
    "\n",
    "# # load the real state dict\n",
    "# model_int8.load_state_dict(torch.load(home+'/outputs/qat.pth'))\n",
    "qnet2 = Net(q=True)\n",
    "load_model(qnet2, model)\n",
    "fuse_modules(qnet2)\n",
    "qnet2.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "va = my_tester(qnet2, trainloader, len(train_data))\n",
    "torch.quantization.prepare(qnet2, inplace=True)\n",
    "torch.quantization.convert(qnet2, inplace=True)\n",
    "qnet2.load_state_dict(torch.load(home+'/outputs/quant_model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
